TITLE: "Graph embeddings as building blocks for decentralized learning".


ABSTRACT:

In recent years, graph neural networks & graph representation learning have seen numerous advances, interesting architectures as well as promising results in various application domains. Concurrently, the paradigm of decentralized or federated Machine Learning has gained enormous momentum due to questions of data security, enhanced privacy-related legislation throughout the world & especially within the EU, but also practical limits of highly centralized cloud infrastructures depending on the availability of "big data". One could conclude that we are seeing the end of an s-curve, with the advent of a succeeding paradigm on the horizon, may it be called distributed-, edge- or decentralized learning. Constructing such systems effectively and efficiently raises the need for data structures amenable to distributed processing. Since real-world graphs are compositional in nature and therefore ideal candidates, this talk will examine how graph embeddings can be used to form meaningful "connection surfaces" between agents (or data silos) on the edge, minimizing exposure of personal data as well as communication overhead. Although the methods presented are currently developed on non-medical data, they are generic in nature and applicable to any ground data that can be expressed as a graph (e.g. cell-graphs extracted from a pathology image). The presenter is currently sponsored by the FeatureCloud project whose goal is the establishment of a secure, cloud-based Federated Learning (FL) infrastructure.


QUESTIONs:

* I the embedding a model -> sometimes yes (unsupervised)
  - can be used directly to infer similarities
  - which can be used for clustering, link prediction etc.
* A *model* generally consists of a set of parameters which in combination have "learned" the decision boundary between positive and negative samples.

